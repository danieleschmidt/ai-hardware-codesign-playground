# Continuous Integration Workflow
# AI Hardware Co-Design Playground
#
# This workflow runs on every push and pull request to ensure code quality,
# run tests, and perform security scans.
#
# MANUAL SETUP REQUIRED:
# Copy this file to .github/workflows/ci.yml

name: Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ============================================================================
  # Code Quality Checks
  # ============================================================================
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev,test]
      
      - name: Install Node.js dependencies
        run: |
          cd frontend
          npm ci
      
      - name: Run Python linting
        run: |
          echo "::group::Black formatting check"
          black --check --diff backend/src/ tests/
          echo "::endgroup::"
          
          echo "::group::isort import sorting check"
          isort --check-only --diff backend/src/ tests/
          echo "::endgroup::"
          
          echo "::group::flake8 linting"
          flake8 backend/src/ tests/
          echo "::endgroup::"
          
          echo "::group::pylint analysis"
          pylint backend/src/
          echo "::endgroup::"
      
      - name: Run Node.js linting
        run: |
          cd frontend
          npm run lint
      
      - name: Run type checking
        run: |
          echo "::group::Python type checking"
          mypy backend/src/
          echo "::endgroup::"
          
          echo "::group::TypeScript type checking"
          cd frontend
          npm run typecheck
          echo "::endgroup::"
      
      - name: Check commit message format
        if: github.event_name == 'pull_request'
        uses: wagoid/commitlint-github-action@v5
        with:
          configFile: '.commitlintrc.json'

  # ============================================================================
  # Security Scanning
  # ============================================================================
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      security-events: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install bandit[toml] safety
      
      - name: Run Bandit security scan
        run: |
          bandit -r backend/src/ -f json -o bandit-report.json
          bandit -r backend/src/ -f txt
        continue-on-error: true
      
      - name: Run Safety dependency scan
        run: |
          safety check --json --output safety-report.json
          safety check
        continue-on-error: true
      
      - name: Run Semgrep security scan
        uses: returntocorp/semgrep-action@v1
        with:
          config: >-
            p/python
            p/javascript
            p/typescript
            p/docker
            p/security-audit
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
        continue-on-error: true
      
      - name: Upload security scan results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json

  # ============================================================================
  # Unit Tests
  # ============================================================================
  test-python:
    name: Python Tests
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ['3.9', '3.10', '3.11', '3.12']
        exclude:
          - os: macos-latest
            python-version: '3.9'
          - os: windows-latest
            python-version: '3.9'
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      - name: Install system dependencies (Ubuntu)
        if: matrix.os == 'ubuntu-latest'
        run: |
          sudo apt-get update
          sudo apt-get install -y verilator
      
      - name: Install system dependencies (macOS)
        if: matrix.os == 'macos-latest'
        run: |
          brew install verilator
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev,test,ml,hardware]
      
      - name: Run unit tests
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
          ENVIRONMENT: test
        run: |
          pytest tests/unit/ -v \
            --cov=backend/src \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --junitxml=junit-python-${{ matrix.os }}-${{ matrix.python-version }}.xml
      
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-python-${{ matrix.os }}-${{ matrix.python-version }}
          path: |
            junit-python-*.xml
            htmlcov/
            coverage.xml
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
        with:
          file: ./coverage.xml
          flags: python
          name: python-${{ matrix.python-version }}

  # ============================================================================
  # Frontend Tests
  # ============================================================================
  test-frontend:
    name: Frontend Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'
      
      - name: Install dependencies
        run: |
          cd frontend
          npm ci
      
      - name: Run unit tests
        run: |
          cd frontend
          npm run test:coverage
      
      - name: Run build test
        run: |
          cd frontend
          npm run build
      
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-frontend
          path: |
            frontend/coverage/
            frontend/junit.xml
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          directory: ./frontend/coverage
          flags: frontend
          name: frontend

  # ============================================================================
  # Integration Tests
  # ============================================================================
  test-integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: integration_password
          POSTGRES_USER: integration_user
          POSTGRES_DB: integration_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y verilator gtkwave
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev,test,ml,hardware]
      
      - name: Run integration tests
        env:
          DATABASE_URL: postgresql://integration_user:integration_password@localhost:5432/integration_db
          REDIS_URL: redis://localhost:6379/0
          ENVIRONMENT: test
        run: |
          pytest tests/integration/ -v \
            --cov=backend/src \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=junit-integration.xml
      
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-integration
          path: |
            junit-integration.xml
            coverage.xml

  # ============================================================================
  # Docker Build Test
  # ============================================================================
  docker-build:
    name: Docker Build
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build development image
        uses: docker/build-push-action@v5
        with:
          context: .
          target: development
          push: false
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:dev
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Build production image
        uses: docker/build-push-action@v5
        with:
          context: .
          target: production
          push: false
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Test Docker images
        run: |
          # Test development image
          docker run --rm ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:dev python --version
          
          # Test production image health check
          docker run -d --name test-container ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          sleep 30
          docker logs test-container
          docker stop test-container
          docker rm test-container

  # ============================================================================
  # Documentation Build
  # ============================================================================
  docs:
    name: Documentation
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[docs]
      
      - name: Build documentation
        run: |
          cd backend
          sphinx-build -W -b html docs/ docs/_build/html
      
      - name: Upload documentation
        uses: actions/upload-artifact@v3
        with:
          name: documentation
          path: backend/docs/_build/html

  # ============================================================================
  # Performance Tests (Optional)
  # ============================================================================
  performance:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    if: github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'performance')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev,test,ml,hardware]
      
      - name: Run performance tests
        run: |
          pytest tests/performance/ -v \
            --benchmark-only \
            --benchmark-json=benchmark-results.json
      
      - name: Store benchmark results
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'pytest'
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: false
          comment-on-alert: true
          alert-threshold: '120%'
          fail-on-alert: true

  # ============================================================================
  # Summary
  # ============================================================================
  ci-success:
    name: CI Success
    runs-on: ubuntu-latest
    needs: 
      - code-quality
      - security
      - test-python
      - test-frontend
      - test-integration
      - docker-build
      - docs
    if: always()
    
    steps:
      - name: Check all jobs
        run: |
          echo "Code Quality: ${{ needs.code-quality.result }}"
          echo "Security: ${{ needs.security.result }}"
          echo "Python Tests: ${{ needs.test-python.result }}"
          echo "Frontend Tests: ${{ needs.test-frontend.result }}"
          echo "Integration Tests: ${{ needs.test-integration.result }}"
          echo "Docker Build: ${{ needs.docker-build.result }}"
          echo "Documentation: ${{ needs.docs.result }}"
          
          if [[ "${{ needs.code-quality.result }}" != "success" || \
                "${{ needs.security.result }}" != "success" || \
                "${{ needs.test-python.result }}" != "success" || \
                "${{ needs.test-frontend.result }}" != "success" || \
                "${{ needs.test-integration.result }}" != "success" || \
                "${{ needs.docker-build.result }}" != "success" || \
                "${{ needs.docs.result }}" != "success" ]]; then
            echo "‚ùå CI pipeline failed"
            exit 1
          else
            echo "‚úÖ CI pipeline passed"
          fi
      
      - name: Report status
        if: always()
        run: |
          if [[ "${{ job.status }}" == "success" ]]; then
            echo "üéâ All CI checks passed! Ready for merge."
          else
            echo "üí• CI pipeline failed. Please fix the issues and try again."
          fi
